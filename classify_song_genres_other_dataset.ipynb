{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_labels = {\"Blues\":0, \n",
    "               \"Classical\":1, \n",
    "               \"Country\":2, \n",
    "               \"Disco\":3, \n",
    "               \"Hip hop\":4, \n",
    "               \"Jazz\":5, \n",
    "               \"Metal\":6, \n",
    "               \"Pop\":7, \n",
    "               \"Reggae\":8,\n",
    "               \"Rock\":9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('melspects.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['x_tr']\n",
    "y = data['y_tr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 64, 173)\n",
      "(8000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(genre_list, song_labels, X, y):\n",
    "    genre_X = []\n",
    "    genre_y = []\n",
    "    for genre in genre_list:\n",
    "        genre_num = song_labels[genre]\n",
    "        inds = np.where(y == genre_num)\n",
    "        sub_X = X[inds, :, :]\n",
    "        sub_X = sub_X.reshape(sub_X.shape[1:]) \n",
    "        sub_y = y[inds]\n",
    "        genre_X.append(sub_X)\n",
    "        genre_y.append(sub_y)\n",
    "    \n",
    "    X = np.concatenate(genre_X, axis = 0)\n",
    "    print(X.shape)\n",
    "        \n",
    "    X = X.reshape((-1, 64, 173, 1))\n",
    "    print(X.shape)\n",
    "        \n",
    "    for i in range(len(genre_y[0])):\n",
    "        genre_y[0][i] = 0\n",
    "        genre_y[1][i] = 1\n",
    "    \n",
    "    y = np.concatenate(genre_y, axis = 0) \n",
    "    print(genre_list[0], ': 0')\n",
    "    print(genre_list[1], ': 1')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 64, 173)\n",
      "(1600, 64, 173, 1)\n",
      "Hip hop : 0\n",
      "Classical : 1\n",
      "(1600, 64, 173)\n",
      "(1600, 64, 173, 1)\n",
      "Metal : 0\n",
      "Jazz : 1\n",
      "(1600, 64, 173)\n",
      "(1600, 64, 173, 1)\n",
      "Pop : 0\n",
      "Hip hop : 1\n",
      "(1600, 64, 173)\n",
      "(1600, 64, 173, 1)\n",
      "Rock : 0\n",
      "Country : 1\n"
     ]
    }
   ],
   "source": [
    "hh_classical = createDataset([\"Hip hop\", \"Classical\"], song_labels, X, y)\n",
    "ds1 = \"Hip hop, Classical\"\n",
    "\n",
    "met_jazz = createDataset([\"Metal\", \"Jazz\"], song_labels, X, y)\n",
    "ds2 = \"Metal, Jazz\"\n",
    "\n",
    "pop_hh = createDataset([\"Pop\", \"Hip hop\"], song_labels, X, y)\n",
    "ds3 = \"Pop, Hip hop\"\n",
    "\n",
    "rock_country = createDataset([\"Rock\", \"Country\"], song_labels, X, y)\n",
    "ds4 = \"Rock, Country\"\n",
    "\n",
    "datasets = [hh_classical, met_jazz, pop_hh, rock_country]\n",
    "dataset_names = [ds1, ds2, ds3, ds4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SillaCNN(input_shape=(64,173,1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExperiment(ds, name, model, epoch):\n",
    "    model = model()\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "                      metrics=['accuracy'])\n",
    "    model.fit(ds[0], ds[1],  batch_size = 32, epochs = epoch, validation_split = 0.3)\n",
    "    model.save(name + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 480 samples\n",
      "Epoch 1/1\n",
      "1120/1120 [==============================] - 64s 57ms/step - loss: 0.6390 - accuracy: 0.9116 - val_loss: 6.0304e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "runExperiment(datasets[0], dataset_names[0], SillaCNN, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 480 samples\n",
      "Epoch 1/1\n",
      "1120/1120 [==============================] - 68s 60ms/step - loss: 0.6993 - accuracy: 0.8571 - val_loss: 7.7622e-08 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "runExperiment(datasets[1], dataset_names[1], SillaCNN, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 480 samples\n",
      "Epoch 1/1\n",
      "1120/1120 [==============================] - 68s 61ms/step - loss: 1.1006 - accuracy: 0.6982 - val_loss: 0.9247 - val_accuracy: 0.0479\n"
     ]
    }
   ],
   "source": [
    "runExperiment(datasets[2], dataset_names[2], SillaCNN, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 480 samples\n",
      "Epoch 1/1\n",
      "1120/1120 [==============================] - 65s 58ms/step - loss: 1.1001 - accuracy: 0.6768 - val_loss: 0.7562 - val_accuracy: 0.2771\n"
     ]
    }
   ],
   "source": [
    "runExperiment(datasets[3], dataset_names[3], SillaCNN, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 480 samples\n",
      "Epoch 1/2\n",
      "1120/1120 [==============================] - 64s 57ms/step - loss: 0.6995 - accuracy: 0.9438 - val_loss: 0.0177 - val_accuracy: 0.9937\n",
      "Epoch 2/2\n",
      "1120/1120 [==============================] - 61s 54ms/step - loss: 0.0422 - accuracy: 0.9884 - val_loss: 0.0981 - val_accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "runExperiment(datasets[0], dataset_names[0], SillaCNN, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 480 samples\n",
      "Epoch 1/2\n",
      "1120/1120 [==============================] - 65s 58ms/step - loss: 0.9660 - accuracy: 0.8250 - val_loss: 2.5056e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "1120/1120 [==============================] - 62s 55ms/step - loss: 0.0637 - accuracy: 0.9723 - val_loss: 0.0258 - val_accuracy: 0.9896\n"
     ]
    }
   ],
   "source": [
    "runExperiment(datasets[1], dataset_names[1], SillaCNN, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 480 samples\n",
      "Epoch 1/2\n",
      "1120/1120 [==============================] - 65s 58ms/step - loss: 1.4795 - accuracy: 0.6911 - val_loss: 2.7208 - val_accuracy: 0.0042\n",
      "Epoch 2/2\n",
      "1120/1120 [==============================] - 63s 57ms/step - loss: 0.3152 - accuracy: 0.8750 - val_loss: 0.5059 - val_accuracy: 0.9250\n"
     ]
    }
   ],
   "source": [
    "runExperiment(datasets[2], dataset_names[2], SillaCNN, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 480 samples\n",
      "Epoch 1/2\n",
      "1120/1120 [==============================] - 64s 58ms/step - loss: 0.9031 - accuracy: 0.7152 - val_loss: 0.3147 - val_accuracy: 0.9271\n",
      "Epoch 2/2\n",
      "1120/1120 [==============================] - 64s 57ms/step - loss: 0.3528 - accuracy: 0.8393 - val_loss: 0.9285 - val_accuracy: 0.4458\n"
     ]
    }
   ],
   "source": [
    "runExperiment(datasets[3], dataset_names[3], SillaCNN, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
